{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-08T13:11:35.087736200Z",
     "start_time": "2023-10-08T13:11:34.884740Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from Networks.MLP import MLP\n",
    "from Networks.CNN import CNN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from Layers.optimizer import *\n",
    "from Layers.util import smooth_curve\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import cupy as np\n",
    "    py = 'cupy'\n",
    "except ImportError:\n",
    "    import numpy as np\n",
    "    py = 'numpy'\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def test(test_list, data_name, max_acc=None):\n",
    "    tr_data, tr_lb, ts_data, ts_lb = set_data(data_name)\n",
    "    tr_size = tr_data.shape[0]\n",
    "    ts_size = ts_data.shape[0]\n",
    "    \n",
    "    networks = {}\n",
    "    train_acc = {}\n",
    "    train_loss = {}\n",
    "    test_acc = {}\n",
    "    test_loss = {}\n",
    "    optimizer = {}\n",
    "    total_step = {}\n",
    "    time_record = {}\n",
    "    print(f'[Training]\\n{py}\\n')\n",
    "    print(f'[Shape]\\ntrain data: {tr_data.shape}\\ntrain label: {tr_lb.shape}\\ntest data: {ts_data.shape}\\ntest label: {ts_lb.shape}')\n",
    "    \n",
    "    for key in test_list.keys():\n",
    "        # 기록 리스트 생성\n",
    "        train_acc[key] = []\n",
    "        train_loss[key] = []\n",
    "        test_acc[key] = []\n",
    "        test_loss[key] = []\n",
    "        total_step[key] = 0\n",
    "        time_record[key] = 0\n",
    "\n",
    "        # nSigmoid 경우 파라미터\n",
    "        # key == 'nSigmoid_8' -> act = nSigmoid, threshold = 8\n",
    "        networks[key] = test_list[key]['network']\n",
    "\n",
    "        # optimizer 생성\n",
    "        opt = test_list[key]['opt']\n",
    "        lr = test_list[key]['lr']\n",
    "        if opt == 'SGD':\n",
    "            optimizer[key] = SGD(lr)\n",
    "        elif opt == 'Momentum':\n",
    "            optimizer[key] = Momentum(lr)\n",
    "        elif opt == 'AdaGrad':\n",
    "            optimizer[key] = AdaGrad(lr)\n",
    "        elif opt == 'Adam':\n",
    "            optimizer[key] = Adam(lr)\n",
    "        else:\n",
    "            assert 'no opt' + opt\n",
    "\n",
    "    # 파라미터 통일 셋팅\n",
    "    # networks1 = networks['1']\n",
    "    # networks2 = networks['2']\n",
    "    # for k in networks1.params.keys():\n",
    "    #     for i in range(networks1.params[k].shape[0]):\n",
    "    #         networks1.params[k][i] = networks2.params[k][i].copy()\n",
    "    # print(np.max(networks['1'].params['W1'] - networks['2'].params['W1']))\n",
    "    # 학습\n",
    "    for i in range(max_iterations):\n",
    "        if 0 not in total_step.values():\n",
    "            print(\"All test list training Done\\nStep: \" + str(i))\n",
    "            break\n",
    "\n",
    "        # mini-batch train\n",
    "        batch_mask = np.random.choice(tr_size, batch_size)\n",
    "        tr_data_b = tr_data[batch_mask]\n",
    "        tr_lb_b = tr_lb[batch_mask]\n",
    "\n",
    "        # mini-batch test\n",
    "        batch_mask_t = np.random.choice(ts_size, batch_size)\n",
    "        ts_data_b = ts_data[batch_mask_t]\n",
    "        ts_lb_b = ts_lb[batch_mask_t]\n",
    "\n",
    "        # print_iter 회마다 경과 출력\n",
    "        if i % print_iter == 0:\n",
    "            print( \"=\"*15 + \"iteration:\" + str(i) + \"=\"*15)\n",
    "            print(\"{:^9}|{:^9}|{:^9}|{:^9}\".format('model','time','acc','loss'))\n",
    "\n",
    "        # 학습 & 추론 & 기록\n",
    "        for key in test_list.keys():\n",
    "            if total_step[key] != 0:\n",
    "                # Max acc 에 도달해 학습이 끝난 test model\n",
    "                continue\n",
    "            else:\n",
    "                start = time.time()\n",
    "                # CV 모델 데이터 처리\n",
    "                if isinstance(networks[key], CNN) and tr_data.ndim == 2:\n",
    "                    tr_data_b = tr_data_b.reshape(-1, 1, 28, 28)\n",
    "                    ts_data_b = ts_data_b.reshape(-1, 1, 28, 28)\n",
    "\n",
    "                # 학습(역전파)\n",
    "                grads = networks[key].gradient(tr_data_b, tr_lb_b)\n",
    "                optimizer[key].update(networks[key].params, grads)\n",
    "\n",
    "                # 추론(순전파)\n",
    "                tr_acc, tr_loss = networks[key].acc_and_loss(tr_data_b, tr_lb_b)\n",
    "                ts_acc, ts_loss = networks[key].acc_and_loss(ts_data_b, ts_lb_b)\n",
    "\n",
    "                # 기록\n",
    "                if py == 'cupy':\n",
    "                    tr_acc = tr_acc.get()\n",
    "                    tr_loss = tr_loss.get()\n",
    "                    ts_acc = ts_acc.get()\n",
    "                    ts_loss = ts_loss.get()\n",
    "                train_acc[key].append(tr_acc)\n",
    "                train_loss[key].append(tr_loss)\n",
    "                test_acc[key].append(ts_acc)\n",
    "                test_loss[key].append(ts_loss)\n",
    "                end = time.time()\n",
    "                time_record[key] += (end-start)\n",
    "\n",
    "                # max accuracy 도달 해당 모델 학습 종료\n",
    "                if max_acc and max_acc <= ts_acc:\n",
    "                    total_step[key] = i\n",
    "                    print(key + \" training end!\\nacc : \" + str(ts_acc) + \" step: \" + str(i))\n",
    "\n",
    "                # print_iter 회마다 경과 출력\n",
    "                if i % print_iter == 0:\n",
    "                    print(\"{:^9}| {:0<7.3f} | {:0<.5f} | {:0<.5f}\".format(key, time_record[key], ts_acc, ts_loss))\n",
    "\n",
    "    return train_acc, train_loss, test_acc, test_loss, total_step\n",
    "\n",
    "\n",
    "def plot(label, datas, t_list, *y_lim):\n",
    "    for key in t_list:\n",
    "        plt.plot(smooth_curve(datas[key]), markevery=50, label=key)\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(label)\n",
    "    if y_lim:\n",
    "        plt.ylim(y_lim)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def set_data(data_name):\n",
    "    if data_name == 'mnist':\n",
    "        (tr_data, tr_lb), (ts_data, ts_lb) = load_mnist(normalize=True)\n",
    "\n",
    "    elif data_name == 'mosquito':\n",
    "        # DATA\n",
    "        data_file = \"C:/Users/dinle/Code/AI/NodeLayer/dataset/mosquito/tensor_image.pt\"\n",
    "        # .pt 파일을 엽니다.\n",
    "        all_data = torch.load(data_file)\n",
    "        all_data = np.array(all_data)\n",
    "        \n",
    "        # label\n",
    "        lb_file = \"C:/Users/dinle/Code/AI/NodeLayer/dataset/mosquito/phase2_train_v0.csv\"\n",
    "        df = pd.read_csv(lb_file)\n",
    "        all_lb = df['class_label']\n",
    "        class_num = {\n",
    "            \"aegypti\":      0,\n",
    "            \"albopictus\":   1,\n",
    "            \"anopheles\":    2,\n",
    "            \"culex\":        3,\n",
    "            \"culiseta\":     4,\n",
    "            \"japonicus/koreicus\": 5\n",
    "        }\n",
    "        all_lb = all_lb.map(class_num)\n",
    "        all_lb = np.array(all_lb)\n",
    "        \n",
    "        # 분리\n",
    "        tr_data = all_data[:2000]\n",
    "        tr_lb = all_lb[:2000]\n",
    "        ts_data = all_data[2000:3000]\n",
    "        ts_lb = all_lb[2000:3000]\n",
    "    else:\n",
    "        assert 'No data'\n",
    "        \n",
    "    return (tr_data, tr_lb, ts_data, ts_lb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T13:11:35.106735500Z",
     "start_time": "2023-10-08T13:11:34.903736100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# data_name = 'mnist'\n",
    "data_name = 'mosquito'\n",
    "batch_size = 100\n",
    "max_iterations = 100\n",
    "print_iter = 10\n",
    "mi = np.arange(max_iterations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T13:11:35.106735500Z",
     "start_time": "2023-10-08T13:11:34.932737700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# net1 = MLP(input_size=784, hidden_size_list=[100, 100, 100, 100], output_size=10,\n",
    "#            use_dropout=False, dropout_ratio=0.5, use_batchnorm=True)\n",
    "# net1 = MLP(input_size=784, hidden_size_list=[100, 100, 100, 100], output_size=10,\n",
    "#             use_dropout=True, dropout_ratio=0.5, use_batchnorm=False)\n",
    "# net2 = CNN(model='CNN3', use_batchnorm=True)\n",
    "net3 = CNN(model='CNN8', input_dim=(3, 224, 224), output_size=6, use_batchnorm=True)\n",
    "# net3 = CNN(model='VGG11', use_batchnorm=True)\n",
    "# net4 = CNN(dropout_ratio=0.5, use_batchnorm=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T13:11:35.106735500Z",
     "start_time": "2023-10-08T13:11:34.949736600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "test_list = {\n",
    "             # 'MLP':\n",
    "             #     {'network':net1,'opt':'AdaGrad','lr':0.01},\n",
    "             # 'SCV':\n",
    "             #     {'network':net2,'opt':'AdaGrad','lr':0.01},\n",
    "             'CNN8':\n",
    "                 {'network':net3,'opt':'AdaGrad','lr':0.01},\n",
    "             # 'CNN_both':\n",
    "             #     {'network':net4,'opt':'AdaGrad','lr':0.01},\n",
    "             }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T13:11:35.106735500Z",
     "start_time": "2023-10-08T13:11:34.964741300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinle\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cupy\\_creation\\from_data.py:46: PerformanceWarning: Using synchronous transfer as pinned memory (6236073984 bytes) could not be allocated. This generally occurs because of insufficient host memory. The original error was: cudaErrorMemoryAllocation: out of memory\n",
      "  return _core.array(obj, dtype, copy, order, subok, ndmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training]\n",
      "cupy\n",
      "\n",
      "[Shape]\n",
      "train data: (2000, 3, 224, 224)\n",
      "train label: (2000,)\n",
      "test data: (1000, 3, 224, 224)\n",
      "test label: (1000,)\n",
      "===============iteration:0===============\n",
      "  model  |  time   |   acc   |  loss   \n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "Out of memory allocating 1,083,801,600 bytes (allocated so far: 13,184,034,816 bytes).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Input \u001B[1;32mIn [30]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# train_acc, train_loss, test_acc, test_loss, total_step = test(test_list)\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train_acc, train_loss, test_acc, test_loss, total_step \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.98\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [26]\u001B[0m, in \u001B[0;36mtest\u001B[1;34m(test_list, data_name, max_acc)\u001B[0m\n\u001B[0;32m     82\u001B[0m     ts_data_b \u001B[38;5;241m=\u001B[39m ts_data_b\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m28\u001B[39m, \u001B[38;5;241m28\u001B[39m)\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# 학습(역전파)\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m grads \u001B[38;5;241m=\u001B[39m \u001B[43mnetworks\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_data_b\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtr_lb_b\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m optimizer[key]\u001B[38;5;241m.\u001B[39mupdate(networks[key]\u001B[38;5;241m.\u001B[39mparams, grads)\n\u001B[0;32m     88\u001B[0m \u001B[38;5;66;03m# 추론(순전파)\u001B[39;00m\n",
      "File \u001B[1;32m~\\Code\\AI\\NodeLayer\\Networks\\CNN.py:271\u001B[0m, in \u001B[0;36mCNN.gradient\u001B[1;34m(self, x, t)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgradient\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, t):\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;66;03m# forward\u001B[39;00m\n\u001B[1;32m--> 271\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_flg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;66;03m# backward\u001B[39;00m\n\u001B[0;32m    274\u001B[0m     dout \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\Code\\AI\\NodeLayer\\Networks\\CNN.py:238\u001B[0m, in \u001B[0;36mCNN.loss\u001B[1;34m(self, x, t, train_flg)\u001B[0m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mloss\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, t, train_flg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 238\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_flg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    239\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_layer\u001B[38;5;241m.\u001B[39mforward(y, t)\n",
      "File \u001B[1;32m~\\Code\\AI\\NodeLayer\\Networks\\CNN.py:234\u001B[0m, in \u001B[0;36mCNN.predict\u001B[1;34m(self, x, train_flg)\u001B[0m\n\u001B[0;32m    232\u001B[0m         x \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mforward(x, train_flg)\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 234\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\Code\\AI\\NodeLayer\\Layers\\layers.py:208\u001B[0m, in \u001B[0;36mConvolution.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrep_b_node\u001B[38;5;241m.\u001B[39mr \u001B[38;5;241m=\u001B[39m N \u001B[38;5;241m*\u001B[39m out_h \u001B[38;5;241m*\u001B[39m out_w\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_reshape_node\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m=\u001B[39m [N, out_h, out_w, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m--> 208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlast_node\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Code\\AI\\NodeLayer\\Nodes\\structure_node.py:47\u001B[0m, in \u001B[0;36mTranspose.forward\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 47\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx_node\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m     y \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[1;32m~\\Code\\AI\\NodeLayer\\Nodes\\structure_node.py:14\u001B[0m, in \u001B[0;36mReshape.forward\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 14\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx_node\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx_shape \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m     16\u001B[0m     y \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\Code\\AI\\NodeLayer\\Nodes\\two_node.py:68\u001B[0m, in \u001B[0;36mAdd.forward\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 68\u001B[0m     a \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ma_node\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb_node\u001B[38;5;241m.\u001B[39mforward()\n\u001B[0;32m     70\u001B[0m     y \u001B[38;5;241m=\u001B[39m a \u001B[38;5;241m+\u001B[39m b\n",
      "File \u001B[1;32m~\\Code\\AI\\NodeLayer\\Nodes\\two_node.py:26\u001B[0m, in \u001B[0;36mDot.forward\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 26\u001B[0m     a \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ma_node\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb_node\u001B[38;5;241m.\u001B[39mforward()\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maT \u001B[38;5;241m=\u001B[39m a\u001B[38;5;241m.\u001B[39mT  \u001B[38;5;66;03m# [128, 100] -> [100, 128]\u001B[39;00m\n",
      "File \u001B[1;32m~\\Code\\AI\\NodeLayer\\Nodes\\structure_node.py:78\u001B[0m, in \u001B[0;36mImg2Matrix.forward\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     75\u001B[0m out_w \u001B[38;5;241m=\u001B[39m (W \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m pad \u001B[38;5;241m-\u001B[39m fw) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m stride \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     77\u001B[0m img \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mpad(x, [(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m), (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m), (pad, pad), (pad, pad)], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconstant\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 78\u001B[0m col \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_h\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_w\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(fh):\n\u001B[0;32m     81\u001B[0m     y_max \u001B[38;5;241m=\u001B[39m i \u001B[38;5;241m+\u001B[39m stride \u001B[38;5;241m*\u001B[39m out_h\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cupy\\_creation\\basic.py:211\u001B[0m, in \u001B[0;36mzeros\u001B[1;34m(shape, dtype, order)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mzeros\u001B[39m(shape, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;124;03m\"\"\"Returns a new array of given shape and dtype, filled with zeros.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \n\u001B[0;32m    199\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    209\u001B[0m \n\u001B[0;32m    210\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 211\u001B[0m     a \u001B[38;5;241m=\u001B[39m \u001B[43mcupy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m     a\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mmemset_async(\u001B[38;5;241m0\u001B[39m, a\u001B[38;5;241m.\u001B[39mnbytes)\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "File \u001B[1;32mcupy\\_core\\core.pyx:132\u001B[0m, in \u001B[0;36mcupy._core.core.ndarray.__new__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mcupy\\_core\\core.pyx:220\u001B[0m, in \u001B[0;36mcupy._core.core._ndarray_base._init\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mcupy\\cuda\\memory.pyx:740\u001B[0m, in \u001B[0;36mcupy.cuda.memory.alloc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mcupy\\cuda\\memory.pyx:1426\u001B[0m, in \u001B[0;36mcupy.cuda.memory.MemoryPool.malloc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mcupy\\cuda\\memory.pyx:1447\u001B[0m, in \u001B[0;36mcupy.cuda.memory.MemoryPool.malloc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mcupy\\cuda\\memory.pyx:1118\u001B[0m, in \u001B[0;36mcupy.cuda.memory.SingleDeviceMemoryPool.malloc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mcupy\\cuda\\memory.pyx:1139\u001B[0m, in \u001B[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._malloc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mcupy\\cuda\\memory.pyx:1384\u001B[0m, in \u001B[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mcupy\\cuda\\memory.pyx:1387\u001B[0m, in \u001B[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: Out of memory allocating 1,083,801,600 bytes (allocated so far: 13,184,034,816 bytes)."
     ]
    }
   ],
   "source": [
    "# train_acc, train_loss, test_acc, test_loss, total_step = test(test_list)\n",
    "train_acc, train_loss, test_acc, test_loss, total_step = test(test_list, data_name, 0.98)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T13:12:36.276771700Z",
     "start_time": "2023-10-08T13:11:34.980736100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot('test_acc', test_acc , test_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T13:12:36.267076200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot('test_loss', test_loss, test_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T13:12:36.298044100Z",
     "start_time": "2023-10-08T13:12:36.296043800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net3.save_params(\"C:/Users/dinle/Code/AI/NodeLayer/params.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T13:12:36.297042200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
